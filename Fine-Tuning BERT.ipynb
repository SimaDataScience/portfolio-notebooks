{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c906a92",
   "metadata": {},
   "source": [
    "## Fine-Tuning BERT for Grammatical Classification\n",
    "\n",
    "We will use a pretrained BERT model from HuggingFace and the Corpus of Linguistic Acceptability (CoLA) to train a model that classifies a sentence's grammatical correctness. As a reminder, CoLA is a collection of \"10657 sentences from 23 linguistics publications, expertly annotated for acceptability (grammaticality) by their original authors\", with the canonical problem being to build a binary classifier.\n",
    "\n",
    "We begin by defining our constants and loading our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f1e8e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import (\n",
    "    TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    ")\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import (\n",
    "    AdamW, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants.\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "DEVICE = torch.device(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'mps' if torch.backends.mps.is_available() \n",
    "    else 'cpu'\n",
    ")\n",
    "DATA_DIR = '/Users/justinsima/dir/datasets/CoLA/raw'\n",
    "\n",
    "# Max number of tokens for each sequence. 512 used by paper.\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Number of batches to use before proceeding to next step (training, validation, testing). \n",
    "# This is for debugging purposes; set to 'None' for full run.\n",
    "MAX_BATCHES = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bfae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data.\n",
    "data_train = pd.read_csv(\n",
    "    os.path.join(data_dir, 'in_domain_train.tsv'),\n",
    "    names=['source', 'label', 'notes', 'sentence'],\n",
    "    delimiter='\\t',\n",
    "    header=None\n",
    ")\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9565fc5a",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We next add our classification (CLS) and seperator (SEP) tokens to our sentences, and tokenize each sample. We'll then convert each token to it's corresponding id in BERT's vocabulary, zero-pad each sequence, and make our masks. Finally, we'll separate our dataset into training and validation sets, and wrap each in a torch DataLoader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ef268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sentences and labels for BERT.\n",
    "sentences = ['[CLS] ' + sentence + ' [SEP]' for sentence in data_train['sentence'].values]\n",
    "labels = data_train['label'].values\n",
    "\n",
    "# Tokenize sentences.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_sentences = [tokenizer.tokenize(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tokens to index in BERT vocabulary.\n",
    "unpadded_sentence_ids = [tokenizer.convert_tokens_to_ids(s) for s in tokenized_sentences]\n",
    "\n",
    "# Pad sequences and create attention masks.\n",
    "sentence_ids = np.array([np.pad(np.array(x).flatten(),\n",
    "                    pad_width =(0, MAX_LEN-len(x)),\n",
    "                    mode='constant',\n",
    "                    constant_values=0.\n",
    "                ) for x in unpadded_sentence_ids])\n",
    "attention_masks = np.array([\n",
    "    np.concatenate(\n",
    "        [np.ones(shape=(len(x))), np.zeros(shape=(MAX_LEN - len(x)))]\n",
    "    ) for x in unpadded_sentence_ids\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ded4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and validation sets.\n",
    "train_features, val_features, train_labels, val_labels, train_masks, val_masks = train_test_split(\n",
    "    sentence_ids,\n",
    "    labels,\n",
    "    attention_masks,\n",
    "    test_size=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a57189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pytorch arrays.\n",
    "train_features = torch.from_numpy(train_features).long()\n",
    "val_features = torch.from_numpy(val_features).long()\n",
    "train_labels = torch.from_numpy(train_labels).long()\n",
    "val_labels = torch.from_numpy(val_labels).long()\n",
    "train_masks = torch.from_numpy(train_masks).long()\n",
    "val_masks = torch.from_numpy(val_masks).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders.\n",
    "dataset_train = TensorDataset(train_features, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(dataset_train)\n",
    "train_loader = DataLoader(dataset=dataset_train, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "dataset_val = TensorDataset(val_features, val_masks, val_labels)\n",
    "val_sampler = RandomSampler(dataset_val)\n",
    "val_loader = DataLoader(dataset=dataset_val, sampler=val_sampler, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d0ee7d",
   "metadata": {},
   "source": [
    "### Training Our Model\n",
    "Now we're ready to fine-tune a BERT model. What follows is a fairly standard training loop using an HuggingFace's AdamW optimizer. Loss on both training and validation sets are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure BERT model.\n",
    "base_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model = nn.DataParallel(base_model)\n",
    "model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68197790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare parameters for training.\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate': 0.1\n",
    "    },\n",
    "    {\n",
    "        'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay_rate': 0.0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5a4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scaler.\n",
    "optimizer = AdamW(\n",
    "    optimizer_grouped_parameters,\n",
    "    lr = 1e-5,\n",
    "    eps = 1e-8\n",
    ")\n",
    "\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be522adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy.\n",
    "def accuracy_score(preds, labels):\n",
    "    class_preds = np.argmax(preds, axis=1).flatten()\n",
    "    class_labels = labels.flatten()\n",
    "    return np.sum(class_preds == class_labels) / len(class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2179313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop.\n",
    "loss_train_list = []\n",
    "loss_val_list = []\n",
    "\n",
    "for epoch in trange(EPOCHS, leave=True, desc='Epoch:'):\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize epoch tracking variables.\n",
    "    time_start = datetime.datetime.now()\n",
    "    loss_train, accuracy_train = 0.0, 0.0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    val_loss, val_accuracy = 0, 0\n",
    "    n_val_steps, b_val_examples = 0, 0\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_loader), leave=True, desc='Batches:'):\n",
    "        # Store tensors and move to device.\n",
    "        batch_sequences, batch_masks, batch_labels = batch[0].to(DEVICE), batch[1].to(DEVICE), batch[2].to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed model and calculate loss / accuracy.\n",
    "        outputs = model(batch_sequences, token_type_ids=None, attention_mask=batch_masks, labels=batch_labels)\n",
    "        loss = outputs['loss']\n",
    "        loss_train_list.append(loss.item())\n",
    "        logits = outputs['logits'].detach().cpu().numpy()\n",
    "        np_labels = batch_labels.to('cpu').numpy()\n",
    "        batch_train_accuracy = accuracy_score(logits, np_labels)\n",
    "        accuracy_train += batch_train_accuracy\n",
    "        \n",
    "        # Backwards step.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "            \n",
    "        # Update train tracking statistics.\n",
    "        loss_train += loss.item()\n",
    "        nb_tr_examples += batch_sequences.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        # TODO: Remove. Only for debugging.\n",
    "        if MAX_BATCHES:\n",
    "            if nb_tr_steps == MAX_BATCHES:\n",
    "                break\n",
    "\n",
    "    time_elapsed = datetime.datetime.now() - time_start\n",
    "                        \n",
    "    # Evaluate each epoch.\n",
    "    model.eval()\n",
    "                        \n",
    "    for batch in val_loader:\n",
    "        batch_sequences, batch_masks, batch_labels = batch[0].to(DEVICE), batch[1].to(DEVICE), batch[2].to(DEVICE)\n",
    "                        \n",
    "        with torch.no_grad():\n",
    "            output = model(batch_sequences, token_type_ids=None, attention_mask=batch_masks, labels=batch_labels)\n",
    "            logits = output['logits'].detach().cpu().numpy()\n",
    "            np_labels = batch_labels.to('cpu').numpy()\n",
    "            \n",
    "            batch_val_accuracy = accuracy_score(logits, np_labels)\n",
    "            batch_val_loss = output['loss']\n",
    "            loss_val_list.append(batch_val_loss.item())\n",
    "            val_loss += batch_val_loss.item()\n",
    "            val_accuracy += batch_val_accuracy\n",
    "            n_val_steps += 1\n",
    "            \n",
    "            # TODO: Remove. Only for debugging.\n",
    "            if MAX_BATCHES:\n",
    "                if n_val_steps == MAX_BATCHES:\n",
    "                    break\n",
    "     \n",
    "    print(f'Epoch: {epoch}, \\\n",
    "        Average Time per Batch: {time_elapsed / len(train_loader)}, \\\n",
    "        Training Loss: {loss_train / len(train_loader)} \\\n",
    "        Training Accuracy: {accuracy_train / len(train_loader)} \\\n",
    "        Validation Loss: {val_loss / len(val_loader)} \\\n",
    "        Validation Accuracy: {val_accuracy / len(val_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training loss.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_train_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation loss.\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(loss_val_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341dc1f8",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We can now prepare our testing data and make predictions. We'll measure our performance on the test set using Matthew's Correlation Coefficient, which is the standard metric for this problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b882452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for model.\n",
    "data_test = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, 'out_of_domain_dev.tsv'),\n",
    "    names=['source', 'label', 'notes', 'sentence'],\n",
    "    delimiter='\\t',\n",
    "    header=None\n",
    ")\n",
    "\n",
    "sentences_test = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in data_test['sentence'].values]\n",
    "labels_test = data_test['label'].values\n",
    "tokenized_sentences_test = [tokenizer.tokenize(sentence) for sentence in sentences_test]\n",
    "\n",
    "unpadded_sentence_ids_test = [tokenizer.convert_tokens_to_ids(s) for s in tokenized_sentences_test]\n",
    "sentence_ids_test = np.array([np.pad(np.array(x).flatten(),\n",
    "                    pad_width =(0, MAX_LEN-len(x)),\n",
    "                    mode='constant',\n",
    "                    constant_values=0.\n",
    "                ) for x in unpadded_sentence_ids_test])\n",
    "attention_masks_test = np.array([\n",
    "    np.concatenate(\n",
    "        [np.ones(shape=(len(x))), np.zeros(shape=(MAX_LEN - len(x)))]\n",
    "    ) for x in unpadded_sentence_ids_test\n",
    "])\n",
    "\n",
    "test_sequences = torch.tensor(sentence_ids_test)\n",
    "test_masks = torch.tensor(attention_masks_test)\n",
    "test_labels = torch.tensor(labels_test)\n",
    "\n",
    "dataset_test = TensorDataset(test_sequences, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(dataset_test)\n",
    "test_loader = DataLoader(dataset_test, sampler=test_sampler, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be442a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set.\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "true_state = []\n",
    "\n",
    "for test_step, batch in tqdm(enumerate(test_loader)):\n",
    "    batch_sequences = batch[0].long().to(DEVICE)\n",
    "    batch_masks = batch[1].long().to(DEVICE)\n",
    "    batch_labels = batch[2].long().to(DEVICE)\n",
    "    \n",
    "    # TODO: Remove. Only for debugging. \n",
    "    if MAX_BATCHES:\n",
    "        if test_step == MAX_BATCHES:\n",
    "            break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(batch_sequences, token_type_ids=None, attention_mask=batch_masks)\n",
    "    \n",
    "    logits = output['logits'].detach().cpu().numpy()\n",
    "    np_labels = batch_labels.to('cpu').numpy()\n",
    "    preds.append(logits)\n",
    "    true_state.append(np_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on the test set using aggregate Matthew's evaluation.\n",
    "flattened_predictions = [item for sublist in preds for item in sublist]\n",
    "flat_predictions = np.argmax(flattened_predictions, axis=1).flatten()\n",
    "flat_true_labels = [item for sublist in true_state for item in sublist]\n",
    "\n",
    "print(f\"Test Matthew's Correlation Coefficient: {matthews_corrcoef(flat_true_labels, flat_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
